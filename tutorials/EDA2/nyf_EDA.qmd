---
author: Simone Santoni
title: Exploratory data analysis of 'New York Flights' dataset
abstract-title: Abstract
abstract: This notebook has a twofold objective. First, to carry out an exploratory data analysis of a popular dataset in data science, namely, 'New York Flights.' Second, to shows how to create some key bivariate data visualizations discussed in Cleveland (1993) by using R's package `ggplot2`.
date: 2024-10-23
format:
  html:
    code-fold: true
    code-tools: true
---

## Notebook setup

### Load packages

To carry out the EDA, we rely on multiple [tidyverse](https://www.tidyverse.org/packages/) packages:

- [`ggplot2`](https://ggplot2.tidyverse.org/) provides core visualization capabilities
- [`tidyr`](https://tidyr.tidyverse.org/) allows create and manipulate data structures, e.g., passing from long (wide) to wide (long) data structures
- [`readr`](https://readr.tidyverse.org/)is a specialistic library to read Comma Separated Value file conveniently and efficiently
- [`dplyr`](https://dplyr.tidyverse.org/) transforms data frames' cases and variables, e.g., by slicing, grouping, summarizing data
- [`tibble`](https://tibble.tidyverse.org/) implements a particular type of data frame, i.e., 'tidy data frames', which are particularly suited for data analysis and visualization

Mainly, the various packages under the 'tidyverse' umbrella offer and integrated set of functionalities supporting the various activities of the data visualization process, from data ingestion to polishing charts.

```{r}
#| warning: false
library(ggplot2)
library(tidyr)
library(readr)
library(dplyr)
```

### Ingest data

We read the tabular data file [`nyc_flights.csv`](https://www.kaggle.com/code/varunmarvah/nyc-flights-dataset-exploratory-analysis), which is a comma-separated value file. First, we check the work directory. Then, we adjust the relative path pointing to the file.

```{r}
getwd()
```

```{r}
nyf = read_csv("../../data/airlinePassengers/nyc_flights.csv")
```

## Key features of the data

The first step of our EDA consists of inspecting a sample of observations, aka a data preview. At this stage, good practices include:

- Interpreting the variables from a business, economic, or social perspective (depending on the nature of the dataset at hand and the project's concrete objectives)
- Understanding the type of each individual column in the data (e.g., string, factor, number)


```{r}
nyf
```

Then, we consider the fundamental aspects of the ingested data, that is, the number of variables (columns), observations (rows), and cases (clusters of rows referring to the same entity). It is worth noticing that the `readr`'s log includes a tabular data file's number of variables and columns 'by default.'

### Number of variables (columns)

To get the number of variables, one can either consider the length of `nyf` or use the `ncol()` function from R's `{base}` package.

```{r}
col_n <- length(nyf) # or ncol(kt)
print(col_n)
```
### Number of observations (rows)

To get the number of observations, one can rely on `dplyr`'s `n_distinct()` function ― not passing any specific column to the function argument ― or `nrow()` from R's `{base}`.

```{r}
row_n <- n_distinct(nyf) # or nrow(kt)
print(row_n)
```

### Check missing values

Understanding how a dataset present missing values is another important EDA task.  `{base}`'s `summary` yields summary statistics for each column in the dataset, and, where present, the number of observations showing missing values.

```{r}
summary(nyf)
```
For example, `dep_delay` and `arr_delay` show some missing values, which we may want to get rid of by using `dplyr`'s `drop_na` function as follows.

```{r}
vars <- c("dep_delay", "arr_delay")
nyf <- nyf |> drop_na(any_of(vars))
```

### Timespan

Inspecting the data preview, it is evident that the dataset is longitudinal, as flight-level datapoints are nested within day-month-year triplets. At least, we may want to double-check how many years and months the dataset spans. To do that, we can use `dplyr`'s `n_distinct()`. Please note that the argument to pass is one or multiple columns included in the tidy data.

```{r}
year_count <- n_distinct(nyf$year)
cat("Counts of years is:", year_count)
```

```{r}
month_count <- n_distinct(nyf$month)
cat("Counts of months is:", month_count)
```
Apparently, the dataset affords flight-level datapoints comprising twelve months from the same calendar year, that is, 2013. Let us double-check the distribution of the datapoints by month.

```{r}
#| label: fig-itemmonth
#| fig-cap: "Distribution of flight-level datapoints by month"
ggplot(data = nyf, mapping = aes(x = factor(month))) + 
  geom_bar()
```

## Explore the association between variables

### Departure vs. arrival delay

The first chart we produce is a 'bare-bone' scatter diagram.

```{r}
#| label: fig-scatter
#| fig-cap: "A bare-bone scatter diagram"
p <- ggplot(data = nyf, mapping = aes(x = dep_delay, y = arr_delay))
p + geom_point()
```
How can we improve this 'bare-bone' bivariate visualizations? There are some non-mutually exclusive options:

+ Create a 2D histogram (see @fig-2dhist) or a 2D kernel density plot (see @fig-2dkde) to cope with over-plotting issues
+ Use `ggplot2`'s `geom_rug()` to the add the univariate distribution for `dep_delay` and `arr_delay` to one of the previously mentioned bivariate visual forms (see @fig-withrug)

```{r}
#| label: fig-2dhist
#| fig-cap: "Joint distribution of departure and arrival delay ― joint histogram"
p + geom_bin2d()
```
```{r}
#| label: fig-2dkde
#| fig-cap: "Joint distribution of departure and arrival delay ― contour plot"
p + geom_density2d()
```
```{r}
#| label: fig-withrug
#| fig-cap: "Joint distribution of departure and arrival delay ― joint histogram and rug plots"
p + geom_bin2d(na.rm = TRUE) + geom_rug()
```

### Arrival delay across weekdays or months

Let us focus on the subset of flights showing a non-trivial delay, say, arbitrarily, two minutes.

```{r}
nyf <- nyf |> filter(arr_delay > 2)
cat("We consider a subset of flights -- N is", nrow(nyf))
```
Then, we plot the distribution of `arr_delay` contingent on `month`. As @fig-boxbymonth shows, `arr_delay`'s distribution is so skewed to make the boxplot hard to read. A possible way to better appreciate the distribution of `arr_delay` is transforming the scale of the y axis ,e.g., by adding `scale_y_log10` to `p` to taking the log(y) (see @fig-boxbymonthlog). Similarly, we can plot the distribution of `arr_delay` contingent on weekdays (see @fig-boxbyday).

```{r}
#| label: fig-boxbymonth
#| fig-cap: "Distribution of arrival delay by month"
p <- ggplot(data = nyf, mapping = aes(y = arr_delay))
p + geom_boxplot() + facet_wrap(~month)
```


```{r}
#| label: fig-boxbymonthlog
#| fig-cap: "Distribution of arrival delay by month (y axis log scaled)"
p <- ggplot(data = nyf, mapping = aes(y = arr_delay))
p + geom_boxplot() + scale_y_log10() + facet_wrap(~month)
```

```{r}
#| label: fig-boxbyday
#| fig-cap: "Distribution of arrival delay by month (y axis log scaled)"
p <- ggplot(data = nyf, mapping = aes(y = arr_delay))
p + geom_boxplot() + scale_y_log10() + facet_wrap(~day)
```

### Arrival delay by month AND weekday

Expanding on the previous section, we plot the distribution of `arr_delay` by `month` *AND* `day`. This requires creating a three-variate visual form. First, we have to summarize `arr_delay` across unique combinations of `month` and `data`:

```{r}
cols <- c("month", "day")
z <- nyf |> group_by(across(all_of(cols))) |> summarize(avg = mean(arr_delay))
print(z)
```
Then, we create a (filled) contour plot showing the variation of `arr_delay` across `month`-`day` combinations (hence, comprising three variables).

```{r}
#| label: fig-trivariate
#| fig-cap: "Distribution of arrival delay by month and weekday -- a contour plot"
p <- ggplot(data = z, mapping = aes(x = month, y = day))
p + geom_contour_filled(aes(z=avg))
```
