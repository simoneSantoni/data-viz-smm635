---
author: Simone Santoni
title: Exploratory data analysis of Koop and Tobias' dataset
abstract-title: Abstract
abstract: This notebook has a twofold objective. First, to carry out an exploratory data analysis of the companion dataset to Koop and Tobias' (2004) article, which deals with the variation in schooling's economic returns. Second, to shows how to create some key data visualizations discussed in Cleveland (1993) by using R's package `ggplot2`.
date: last-modified
format: 
  html:
    fig-width: 6
    fig-height: 4
    code-fold: true
---

## Notebook setup

### Load packages

To carry out the EDA, we rely on multiple [tidyverse](https://www.tidyverse.org/packages/) packages:

- [`ggplot2`](https://ggplot2.tidyverse.org/) provides core visualization capabilities
- [`tidyr`](https://tidyr.tidyverse.org/) allows create and manipulate data structures, e.g., passing from long (wide) to wide (long) data structures
- [`readr`](https://readr.tidyverse.org/)is a specialistic library to read Comma Separeted Value file conveniently and efficiently
- [`dplyr`](https://dplyr.tidyverse.org/) transforms data frames' cases and variables, e.g., by slicing, grouping, summarizing data
- [`tibble`](https://tibble.tidyverse.org/) implements a particular type of data frame, i.e., 'tidy data frames', which are particularly suited for data analysis and visualization

Mainly, the various packages under the 'tidyverse' umbrealla offer and integrated set of functionalities supporting the various activities of the data visualization process, from data ingestion to polishing charts.

```{r}
#| warning: false
library(ggplot2)
library(tidyr)
library(readr)
library(dplyr)
```

### Ingest data

We read the tabular data file provided by Koop and Tobias, which is a comma-separated value file. First, we check the work directory. Then, we adjust the relative path pointing to the file.

```{r}
getwd()
```

```{r}
kt = read_csv("../data/koopAndTobias/koop_tobias.csv")
```

## Key features of the data

The first step of our EDA consists of inspecting a sample of observations, aka a data preview. At this stage, good practices include:

- Interpreting the variables from a business, economic, or social perspective (depending on the nature of the dataset at hand and the project's concrete objectives)
- Understanding the type of each individual column in the data (e.g., string, factor, number)


```{r}
kt
```

Then, we consider the fundamental aspects of the ingested data, that is, the number of variables (columns), observations (rows), and cases (clusters of rows referring to the same entity). It is worth noticing that the `readr`'s log includes a tabular data file's number of variables and columns 'by default.'

### Number of variables (columns)

To get the number of variables, one can either consider the length of `kt` or use the `ncol()` function from R's `{base}` package.

```{r}
col_n <- length(kt) # or ncol(kt)
print(col_n)
```
### Number of observations (rows)

To get the number of observations, one can rely on `dplyr`'s `n_distinct()` function ― not passing any specific column to the function argument ― or `nrow()` from R's `{base}`.

```{r}
row_n <- n_distinct(kt) # or nrow(kt)
print(row_n)
```
### Number of unique cases (clusters of rows referring to the same entity)

To count the number of cases in the data, individuals in Koop and Tobias' data, one has to consider the number of unique values in the column containing the case identifiers (represented by numbers). `dplyr`'s `n_distinct()` is a good alternative to do that. Please note that the argument to pass is one or mulitple columns included in the tidy data.

```{r}
cases <- n_distinct(kt$PERSONID)
print(cases)
```

### Wrap info regarding data's key features

With the help of `tibble`'s `tribble` function, it is possible to wrap up the previously calculated quantities into a single data frame, which we may want to use for further calculcation and/or for illustrative purposes.

```{r}
key_features <- tribble(
  ~Observations, ~Variables, ~Cases,
  row_n, col_n, cases
)
print(key_features)
```

## Assess the distribution of measurement occasions by case

The data object `kt` does not contain any columns indicating the number of times that each individual was observed. Hence, we have to create a new data object to conveniently use as input for a `ggplot2` figure. The following code cell shows how to use a `dplyr` pipeline to group `kt` data around the variable `PERSONID` and to count the number of observations per `PERSONID` instance. Not suprisingly, we achieve a data object containing as many observations as unique values in `kt$PERSONID`. Students are encouraged to familiarize themeselves with `dplyr`. The [cheatsheet](https://) is a good place to start. Caveat: all throughout the various sections of this notebook, limited attention is devoted to aestethic features of the plots. In other words, we will deal with bare-bone `ggplot2` charts. A separate notebook covers the fine-tuning of `ggplot2`'s plots.

```{r}
#| label: fig-indmeas
#| fig-cap: "Distribution of cases by measurement occasions"
#| warning: false
obs <- kt |>
  group_by(PERSONID) |>
  count()
ggplot(data = obs, mapping = aes(x = n)) +
  geom_bar()
```

## Assess the distribution of the higher education level attained

The distribution of `EDUC` is time variant in the data. In other words, the same individual can present different levels of `EDUC` across measurement occasions. Thus, it may be important to appreciate the highest education level each individual attained. To do so, we create a `dplyr` pipeline that groups the datapoints around `PERSONID` and summarize the records by retaining the max of `EDUC` by `PERSONID`.

```{r}
#| label: fig-maxed
#| fig-cap: "Distribution of cases by highest education level attained"
#| warning: false
max_ed <- kt |>
  group_by(PERSONID) |>
  summarise(max = max(EDUC))
ggplot(data = max_ed, mapping = aes(x = max)) +
  geom_bar()
```

## Distribution of log(hourly wage)

### Univariate plots

There are alternative univariate visual forms that we can use to appreciate the distribution of `LOGWAGE`, such as:

- Quantile plot
- Histogram
- Kernel density 
- Boxplot

The latter three alternatives are included in `ggplot2`, while we need to implement the quantile plot visual form on our own.

#### Quantile plot

The quantile plot comprises two data series, the array of probabilities $F = \{f_{1}, f_{2}, ..., f_{i}, ..., f_{K}\}$ and the corresponding quantiles $q(f)$ in the (sample) distribution of interest $x$. The below-displayed code cell the numerical progression `seq` ― i.e., $f$ ― by means of the function `seq` (included in R's `{base}`). Then, it passes `seq` to `quantile`'s argument (includedin R's `{base}`) to compute $q(f)$. At this point, it is possible to implement the quantile plot in `ggplto2` with `geom_point()`.


```{r}
#| label: fig-quantileplot
#| fig-cap: "Distribution of LOGWAGE -- a quantile plot"
#| warning: false
seq <- seq(0, 1, 0.05)
qf <- tibble(f = seq, qf = quantile(kt$LOGWAGE, probs = seq, names = FALSE))
ggplot(data = qf, mapping = aes(x = f, y = qf)) +
  geom_point()
```

#### Histogram and kernel density plots

Histograms are another popular univariate visual forms to plot the distribution of a continuous variable like `LOGWAGE`. @fig-hist and @fig-kde show a traditional histogram and the kernel density plot of the histogram of `LOGWAGE`, respectively.

```{r}
#| label: fig-hist
#| fig-cap: "Distribution of LOGWAGE -- a histogram"
#| warning: false
ggplot(data = kt, mapping = aes(x = LOGWAGE)) +
  geom_histogram()
```


```{r}
#| label: fig-kde
#| fig-cap: "Distribution of LOGWAGE -- a kernel denssity plot"
#| warning: false
ggplot(data = kt, mapping = aes(x = LOGWAGE)) +
  geom_density(kernel = "gaussian")
```

#### Boxplot

The boxplot, presented in @fig-boxplot, is yet another way of plotting the univariate distribution of a continuous variable. As described in Cleveland (1993), the boxplot can be seen as simplified version of the quantile plot form. It is a simplified version in the sense it provides information on three quantiles (the lower quartile, the median, and the upper quantile of a sample distribution $x$) and two other reference values, that is, the lower and upper adjacent values (i.e., the sample values closer to but not less than $-1.5 * q(75) - q(25)$, and closer to but not larger than $1.5 * q(75) - q(25)$)

```{r}
#| label: fig-boxplot
#| fig-cap: Distribution of LOGWAGE -- a boxplot
#| warning: false
ggplot(data = kt, mapping = aes(y = LOGWAGE)) +
  geom_boxplot(orientation = "x")
```

### Associations between log(hourly wage) and other variables

Considering the dataset at hand, possible bivariate visual forms regard the association/correlation between `LOGWAGE` and `EDUC`. When both variables are continuous, a scatter diagram like @fig-scatter would be a plausible visual form. However, when one variable is continuous and the other is discrete, it is more appropriate to draw a series of boxplots, as shown in @fig-boxplot, or violin plots, as shown in @fig-violinplot, which can be thought as vertically-oriented kernel density plots.

#### -- individual's education

```{r}
#| label: fig-scatter
#| fig-cap: "Association between LOGWAGE and EDU -- scatter diagram"
#| warning: false
ggplot(data = kt, mapping = aes(x = EDUC, y = LOGWAGE)) +
  geom_point() +
  geom_smooth(formula = y ~ x, method = lm)
```

```{r}
#| label: fig-eduasfactor
#| fig-cap: "Distribution of LOGWAGE conditional on EDU levels -- a boxplot plot"
#| warning: false
ggplot(data = kt, mapping = aes(x = factor(EDUC), y = LOGWAGE)) +
  geom_boxplot()
```

```{r}
#| label: fig-violinplot
#| fig-cap: "Distribution of LOGWAGE conditional on EDU levels -- a violin plot"
#| warning: false
ggplot(data = kt, mapping = aes(x = factor(EDUC), y = LOGWAGE)) +
  geom_violin(scale = "area")
```

### Trivariate visual form example

Using `ggplot2`'s faceting capabilities, we may want to compare two associations: how `LOGWAGE` varies across `FATHERED` and `MOTHERED`, that is, an individual's father and mother education, respectively. However, the data at hand are not arranged to facilitate the creating of a `ggplot2` plot with faceting. What we need would be a 'long' format data table looking like the following:

| PERSONID | LOGWAGE | PARENT | PARENT EDUCATION |
| :------: | :-----: | :----: | :--------------: |
| 1        | 1.82    | Father | 12               |
| 1        | 1.82    | Mother | 11               |
| 2        | 2.14    | Father | 14               |
| 2        | 2.14    | Mother | 15               |

However, we have a 'wide' format data table:

| PERSONID | LOGWAGE | FATHERED | MOTHERED         |
| :------: | :-----: | :----:   | :--------------: |
| 1        | 1.82    | 12       | 11               |
| 2        | 2.14    | 14       | 15               |

Clearly, the latter data structure does not provide us with any suited columns to pass to the faceting parameter of a `ggplot2` plot. The former does, though. To achieve a 'long' format data table, we rely on `tidyr`'s function `pivot_longer`, which stacks `FATHERED` and `MOTHERED` datapoints 'vertically' and place them in the same column of a tidy dataframe. Moreover, `pivot_longer` creates a second column adjudicating between 'father' or 'mother' datapoints.

```{r}
kt_pivot <- kt |>
  select(PERSONID, LOGWAGE, MOTHERED, FATHERED) |>
  pivot_longer(cols = ends_with("ED"))

ggplot(data = kt_pivot, mapping = aes(x = factor(value), y = LOGWAGE)) +
  geom_boxplot() +
  facet_wrap(~name, ncol = 2)
```

## References

Cleveland, William S. Visualizing data. Hobart press, 1993.

Koop, Gary, and Justin L. Tobias. "Learning about heterogeneity in returns to schooling." Journal of Applied Econometrics 19, no. 7 (2004): 827-849.


